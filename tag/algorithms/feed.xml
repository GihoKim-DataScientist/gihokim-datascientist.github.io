<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://gihokim-datascientist.github.io/tag/algorithms/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://gihokim-datascientist.github.io/" rel="alternate" type="text/html" />
  <updated>2021-05-13T09:09:11-07:00</updated>
  <id>https://gihokim-datascientist.github.io/tag/algorithms/feed.xml</id>

  
  
  

  
    <title type="html">Giho’s Data Science Notes | </title>
  

  
    <subtitle>주니어 데이터 사이언티스트 김기호의 컴퓨터 공부 일기</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Machine Learning Algorithm - linear regression (4)</title>
      <link href="https://gihokim-datascientist.github.io/algorithm-linear-regression-4" rel="alternate" type="text/html" title="Machine Learning Algorithm - linear regression (4)" />
      <published>2021-04-13T13:40:00-07:00</published>
      <updated>2021-04-13T13:40:00-07:00</updated>
      <id>https://gihokim-datascientist.github.io/algorithm-linear-regression-4</id>
      <content type="html" xml:base="https://gihokim-datascientist.github.io/algorithm-linear-regression-4">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Algorithms 구성 &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithms-basic&quot;&gt;Algorithms (1) - Machine learning basic 기초&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-1&quot;&gt;Algorithms (2) - Machine learning linear regression (1)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-2&quot;&gt;Algorithms (2) - Machine learning linear regression (2)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-3&quot;&gt;Algorithms (2) - Machine learning linear regression (3)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-4&quot;&gt;Algorithms (2) - Machine learning linear regression (4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;결정계수-coefficient-of-determination-r2&quot;&gt;결정계수 (coefficient of determination: R^2)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Yi = 실제 Y 값&lt;/li&gt;
  &lt;li&gt;두번째 점은 모델링에서 나온 ^Y값&lt;/li&gt;
  &lt;li&gt;Y bar은 실제 Y값의 평균값&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images//linear_regression/fourth_linear_regression1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;r2&quot;&gt;R^2&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SSE = 실제 Y값과 모델의 ^Y 값들의 차이의 제곱 합&lt;/li&gt;
  &lt;li&gt;SSR = 모델의 ^Y값과 실제 Y의 평균값과의 차이의 제곱 합&lt;/li&gt;
  &lt;li&gt;SST = SSR + SSE&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ssr--sst--r2&quot;&gt;SSR / SST = R^2&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;1인 경우: SST = SSR + (SSE = 0); model의 직선이 실제 Y값들을 지나감 (확정적인 관계)
현재 가지고 있는 x변수로 y를 100% 설명, 모든 y가 linear regression line위에 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images//linear_regression/fourth_linear_regression2.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0인 경우: SST = (SSR = 0) + SSE; model의 직선이 Y값의 평균을 지나감 (parameter x가 아무런 y에 효과가 없음)
현재 가지고 있는 x변수는 y를 설명(예측)에 전혀 도움이 되지않는다&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;사용하고 있는 x변수가 y변수의 variance를 얼마나 줄였는지 정도&lt;/li&gt;
  &lt;li&gt;단순히 y의 평균값을 사용했을 때 대비 x정보를 사용함으로써 얻는 성능 향상 정도&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;수정-결정계수-adjusted-r2&quot;&gt;수정 결정계수 (Adjusted R^2)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images//linear_regression/fourth_linear_regression4.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;R^2는 의미없는 변수 x가 추가되어도 항상 증가한다&lt;/li&gt;
  &lt;li&gt;수정 R^2는 의미없는 변수 x가 추가되었을때 R^2가 증가하는것을 방지하기위해 특정 계수를 식앞에 곱해줌&lt;/li&gt;
  &lt;li&gt;의미있는 변수 x가 추가되었을때는 SSE값이 떨어지기 때문에 전체 adj R^2는 증가하게 된다&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;예제&quot;&gt;예제&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images//linear_regression/fourth_linear_regression5.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;parameter x1 (판매원 수)와 x2 (광고비) 에 의해 y (매출액)의 variance가 68.3% 감소&lt;/li&gt;
  &lt;li&gt;매출액의 평균 (y bar)에 대비 x1, x2 parameter를 이용하면 설명력이 68.3% 증가&lt;/li&gt;
  &lt;li&gt;현재 분석에 사용하고 있는 판매원 수와 광고비는 “변수 품질”정도가 68.3 (100점 기준)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;분산-분석-analysis-of-variance&quot;&gt;분산 분석 (analysis of variance)&lt;/h1&gt;

&lt;h3 id=&quot;ssr--sse-x-변수에-의해-설명된-것--에러에-의한-설명된-것&quot;&gt;SSR / SSE (x 변수에 의해 설명된 것 / 에러에 의한 설명된 것)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SSR / SSE &amp;gt; 1
    &lt;ol&gt;
      &lt;li&gt;SSR &amp;gt; SSE; x변수가 y변수에 statistically significant&lt;/li&gt;
      &lt;li&gt;x변수의 기울기가 0이 아님 -&amp;gt; reject null hypothesis&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;0 &amp;lt;= SSR / SSE &amp;lt;= 1
    &lt;ol&gt;
      &lt;li&gt;SSR &amp;lt; SSE; x변수가 y변수에 not statistically significant&lt;/li&gt;
      &lt;li&gt;x변수의 기울기가 0 -&amp;gt; null hypothesis is true&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>GihoKim</name>
        
        
      </author>

      

      
        <category term="algorithms" />
      

      
        <summary type="html">Algorithms 구성 Algorithms (1) - Machine learning basic 기초 Algorithms (2) - Machine learning linear regression (1) Algorithms (2) - Machine learning linear regression (2) Algorithms (2) - Machine learning linear regression (3) Algorithms (2) - Machine learning linear regression (4)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine Learning Algorithm - linear regression (3)</title>
      <link href="https://gihokim-datascientist.github.io/algorithm-linear-regression-3" rel="alternate" type="text/html" title="Machine Learning Algorithm - linear regression (3)" />
      <published>2021-04-13T11:40:00-07:00</published>
      <updated>2021-04-13T11:40:00-07:00</updated>
      <id>https://gihokim-datascientist.github.io/algorithm-linear-regression-3</id>
      <content type="html" xml:base="https://gihokim-datascientist.github.io/algorithm-linear-regression-3">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Algorithms 구성 &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithms-basic&quot;&gt;Algorithms (1) - Machine learning basic 기초&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-1&quot;&gt;Algorithms (2) - Machine learning linear regression (1)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-2&quot;&gt;Algorithms (2) - Machine learning linear regression (2)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-3&quot;&gt;Algorithms (2) - Machine learning linear regression (3)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-4&quot;&gt;Algorithms (2) - Machine learning linear regression (4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;parameter-estimation-algorithms&quot;&gt;Parameter Estimation Algorithms&lt;/h1&gt;

&lt;p&gt;Least squared estimator&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;estimator: a function of the samples&lt;/li&gt;
  &lt;li&gt;purpose of estimator: to find out unknown parameters&lt;/li&gt;
  &lt;li&gt;types of estimator
    &lt;ol&gt;
      &lt;li&gt;point estimator (점 추정)&lt;/li&gt;
      &lt;li&gt;interval estimator (구간 추정)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;point-estimator&quot;&gt;point estimator&lt;/h3&gt;

&lt;h4 id=&quot;yi--w0--w1-xi--εi-εi--n0-σ-i--1-2--n&quot;&gt;Yi = w0 + w1 Xi + εi, εi ~ N(0, σ²), i = 1, 2, … n&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;w0 에 대한 point estimator: ^w0 = mean(y) - ^w1 * mean(x)&lt;/li&gt;
  &lt;li&gt;w1 에 대한 point estimator: linear regression 2 참조&lt;/li&gt;
  &lt;li&gt;σ²에 대한 point estimator: ^σ²= (1 / n - 2) sum ( ei²) -&amp;gt; residual&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;interval-estimation&quot;&gt;Interval Estimation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;구간으로 측정하여 보다 유연한 정보 제공&lt;/li&gt;
  &lt;li&gt;θ (parameter)에 대한 구간 측정 -&amp;gt; ^θ - 상수값 * std(θ) &amp;lt;= θ &amp;lt;= ^θ + 상수값 * std(θ)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;기울기에-대한-가설검정&quot;&gt;기울기에 대한 가설검정&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;unknown parameter에 대한 가설을 세우고 이를 검정&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;p-value&quot;&gt;p-value&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;p-value가 0.05나 0.01보다 작으면 reject null hypothesis&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;statsmodelsformulaapi에-ols-function을-통한-모델링을-했을때&quot;&gt;statsmodels.formula.api에 ols function을 통한 모델링을 했을때&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images//linear_regression/thrid_linear_regression1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;parameters: wet, frs, cld, intercept&lt;/li&gt;
  &lt;li&gt;point estimates: 각각의 coef&lt;/li&gt;
  &lt;li&gt;std: 각각의 std err&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/thrid_linear_regression4.png&quot; alt=&quot;png&quot; /&gt;
&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/thrid_linear_regression3.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;t: 전반적으로 모든 parameters들의 abs(t)값이 &amp;gt; 1.96 (p &amp;lt; 0.05) 또는 abs(t) &amp;gt; 2.58 (p &amp;lt; 0.01) 큼 -&amp;gt; null hypothesis를 reject&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/thrid_linear_regression2.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;p-value: 모든 slope parameters이 0.05보다 큰 값이 없기 때문에 statistically significant&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>GihoKim</name>
        
        
      </author>

      

      
        <category term="algorithms" />
      

      
        <summary type="html">Algorithms 구성 Algorithms (1) - Machine learning basic 기초 Algorithms (2) - Machine learning linear regression (1) Algorithms (2) - Machine learning linear regression (2) Algorithms (2) - Machine learning linear regression (3) Algorithms (2) - Machine learning linear regression (4)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine Learning Algorithm - linear regression (2)</title>
      <link href="https://gihokim-datascientist.github.io/algorithm-linear-regression-2" rel="alternate" type="text/html" title="Machine Learning Algorithm - linear regression (2)" />
      <published>2021-04-13T08:40:00-07:00</published>
      <updated>2021-04-13T08:40:00-07:00</updated>
      <id>https://gihokim-datascientist.github.io/algorithm-linear-regression-2</id>
      <content type="html" xml:base="https://gihokim-datascientist.github.io/algorithm-linear-regression-2">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Algorithms 구성 &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithms-basic&quot;&gt;Algorithms (1) - Machine learning basic 기초&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-1&quot;&gt;Algorithms (2) - Machine learning linear regression (1)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-2&quot;&gt;Algorithms (2) - Machine learning linear regression (2)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-3&quot;&gt;Algorithms (2) - Machine learning linear regression (3)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-4&quot;&gt;Algorithms (2) - Machine learning linear regression (4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;parameter-estimate-algorithms&quot;&gt;Parameter Estimate Algorithms&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;mean squared error&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/second_linear_regression1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;function H(x)를 w0 + w1 X1으로 두었기 때문에&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/second_linear_regression2.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이런식으로 바뀌게 되는것을 알 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;to-find-best-fit-line&quot;&gt;To find best fit line&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;cost function을 MSE로 썻기 때문에 parabola 형태를 뛴 그래프 형태가 될 것이다&lt;/li&gt;
  &lt;li&gt;gradient descent를 적용 w0과 w1에 대한 partial derivative를 각각 구한다&lt;/li&gt;
  &lt;li&gt;partial derivative = 0 꼴로 만들고 w0과 w1으로 풀어쓰게 되면 w0과 w1에 대한 식이 생겨남&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/second_linear_regression3.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;^Y = ^w0 + ^w1 X 꼴의 식이 성립된다&lt;/p&gt;

&lt;h1 id=&quot;least-squared-estimation-algorithm-최소제곱법&quot;&gt;Least squared Estimation Algorithm (최소제곱법)&lt;/h1&gt;

&lt;h3 id=&quot;residual-잔차&quot;&gt;Residual (잔차)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;e = y - ^y 최소 제곱법으로 구해진 직선의 ^Y와 실제 Y값의 차이 (정해진 값)&lt;/li&gt;
  &lt;li&gt;ε = y - E(y) 오차항은 확률 분포를 따름&lt;/li&gt;
  &lt;li&gt;잔차 e는 확률 오차 ε이 실제로 구현된 값&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/second_linear_regression4.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>GihoKim</name>
        
        
      </author>

      

      
        <category term="algorithms" />
      

      
        <summary type="html">Algorithms 구성 Algorithms (1) - Machine learning basic 기초 Algorithms (2) - Machine learning linear regression (1) Algorithms (2) - Machine learning linear regression (2) Algorithms (2) - Machine learning linear regression (3) Algorithms (2) - Machine learning linear regression (4)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine Learning Algorithm - linear regression (1)</title>
      <link href="https://gihokim-datascientist.github.io/algorithm-linear-regression-1" rel="alternate" type="text/html" title="Machine Learning Algorithm - linear regression (1)" />
      <published>2021-04-13T05:40:00-07:00</published>
      <updated>2021-04-13T05:40:00-07:00</updated>
      <id>https://gihokim-datascientist.github.io/algorithm-linear-regression-1</id>
      <content type="html" xml:base="https://gihokim-datascientist.github.io/algorithm-linear-regression-1">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Algorithms 구성 &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithms-basic&quot;&gt;Algorithms (1) - Machine learning basic 기초&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-1&quot;&gt;Algorithms (2) - Machine learning linear regression (1)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-2&quot;&gt;Algorithms (2) - Machine learning linear regression (2)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-3&quot;&gt;Algorithms (2) - Machine learning linear regression (3)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-4&quot;&gt;Algorithms (2) - Machine learning linear regression (4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;linear-regression-선형-회귀&quot;&gt;Linear regression (선형 회귀)&lt;/h1&gt;

&lt;h3 id=&quot;변수-사이의-관계&quot;&gt;변수 사이의 관계&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;확정적 관계&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;x 변수만으로 y를 100% 표현 (오차 없음)&lt;/p&gt;

&lt;p&gt;ex) force = f(mass, acceleration), distance = f(velocity, time)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;확률적 관계&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ex) 포도주 가격 = f(강우량, 온도, 포도품종) + ε&lt;/p&gt;

&lt;h1 id=&quot;francis-galton&quot;&gt;Francis Galton&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/linear_regression_(1).png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;relationship of height between father and son&lt;/p&gt;

&lt;h1 id=&quot;선형-회귀-모델-linear-regression&quot;&gt;선형 회귀 모델 (linear regression)&lt;/h1&gt;

&lt;h3 id=&quot;선형회귀-모델-출력변수-y를-입력변수-x들의-선형-결합으로-표현한-모델&quot;&gt;선형회귀 모델: 출력변수 Y를 입력변수 x들의 선형 결합으로 표현한 모델&lt;/h3&gt;

&lt;h4 id=&quot;선형결합-변수들을-상수-배와-더하기-빼기를-통해-결합&quot;&gt;선형결합: 변수들을 (상수 배와) 더하기 빼기를 통해 결합&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      Y = B + B1 X1 + B2 X2 + ... Bp Xp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;x 변수가 한개 인 경우: Y = B0 + B1 X (직선식)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;B0 = intercept (절편), B1 = slope (기울기)&lt;/p&gt;

&lt;h3 id=&quot;purpose-of-linear-regression&quot;&gt;purpose of linear regression&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;to interpret the relationship between x and y&lt;/li&gt;
  &lt;li&gt;to predict the output value y&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;regression-model-types&quot;&gt;Regression model types&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/linear_regression_(2).png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형회귀는 가장 데이터에 알맞은 함수 (line)를 찾는 것
(Find the best fit line of different lines)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/linear_regression/linear_regression_(3).png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>GihoKim</name>
        
        
      </author>

      

      
        <category term="algorithms" />
      

      
        <summary type="html">Algorithms 구성 Algorithms (1) - Machine learning basic 기초 Algorithms (2) - Machine learning linear regression (1) Algorithms (2) - Machine learning linear regression (2) Algorithms (2) - Machine learning linear regression (3) Algorithms (2) - Machine learning linear regression (4)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine Learning Algorithm - 기초 Basic</title>
      <link href="https://gihokim-datascientist.github.io/algorithms-basic" rel="alternate" type="text/html" title="Machine Learning Algorithm - 기초 Basic" />
      <published>2021-04-12T09:40:00-07:00</published>
      <updated>2021-04-12T09:40:00-07:00</updated>
      <id>https://gihokim-datascientist.github.io/algorithms-basic</id>
      <content type="html" xml:base="https://gihokim-datascientist.github.io/algorithms-basic">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Algorithms 구성 &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithms-basic&quot;&gt;Algorithms (1) - Machine learning basic 기초&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-1&quot;&gt;Algorithms (2) - Machine learning linear regression (1)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-2&quot;&gt;Algorithms (2) - Machine learning linear regression (2)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-3&quot;&gt;Algorithms (2) - Machine learning linear regression (3)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./algorithm-linear-regression-4&quot;&gt;Algorithms (2) - Machine learning linear regression (4)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;모델링이란&quot;&gt;모델링이란?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;주어진 독립변수, 예측변수, input 변수 (predictor variables) x&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;주어진 종속변수 반응변수 output 변수 (response variables) y 를 가지고&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;알맞은 함수식 (hypothesis function or prediction rule) function f(x) 를 찾는것&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;training-data-and-testing-data&quot;&gt;Training data and Testing data&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Training data (학습 데이터)는 모델 f(x)구축시 사용되는 데이터&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Testing data (검증 데이터)는 구축된 모델을 검증하는데 사용되는 데이터&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ai란&quot;&gt;AI란?&lt;/h2&gt;
&lt;p&gt;Artifical intelligence는 어느 기계에 함수가 들어가는 것 (세탁기에 함수가 들어가면 인공지능 세탁기가 된다!)&lt;/p&gt;

&lt;h1 id=&quot;모델링의-종류&quot;&gt;모델링의 종류&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;linear regression (선형 회귀)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;logistic regression (로지스틱 회귀)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;decision tree (의사결정나무)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;random forest (랜덤 포레스트)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;network (네트워크 모델 #신경망모델)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;데이터&quot;&gt;데이터&lt;/h1&gt;
&lt;h3 id=&quot;y의-종류&quot;&gt;y의 종류&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;연송형 (quantitative) : 숫자로 표현 (가격, 길이, 압력, 두께)&lt;/li&gt;
  &lt;li&gt;범주형 (categorical): 숫자로 표현 안되는 데이터 (제품 불량 여부, 보험 사기 여부)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;regression-수치-예측&quot;&gt;regression (수치 예측)&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;큰 의미의 수치 예측&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;classification-범주-예측-분류&quot;&gt;classification (범주 예측, 분류)&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;0 = 불량, 1 = 정상&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;regression-example&quot;&gt;regression example&lt;/h1&gt;

&lt;p&gt;모델을 만들고 x값을 넣었을때 numerical y값을 구하는 모델&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/basic1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;classification-example&quot;&gt;classification example&lt;/h1&gt;

&lt;p&gt;두 종류를 나눠주는 모델을 만들고 데이터가 주어졌을때 그 것이 어느 종류인지 알려주는 모델&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../jupyterimages/algorithms_images/basic2.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;features--특성들을-바탕으로-불량품인지-아닌지-또는-정상인지-비정상인지-종류를-예측-하는-모델&quot;&gt;features  (특성들)을 바탕으로 불량품인지 아닌지 또는 정상인지 비정상인지 ‘종류’를 예측 하는 모델&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;x 와 y 의 관계를 찾자&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;y를 설명하는 x 변수는 보통 여러개 이다&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;여러 종류의 x를 가지고 y와의 관계를 찾는 것&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Y = f(X1, X2, … Xp)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;parameters-매개-변수&quot;&gt;Parameters (매개 변수)&lt;/h1&gt;
&lt;h3 id=&quot;coefficient--parameters-include-intercept&quot;&gt;coefficient = parameters (include intercept)&lt;/h3&gt;

&lt;p&gt;Y = w1 X1 + w2 X2 + ε&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;여기서는 w1 과 w2가 parameter, ε은 오차 (error)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;모델의 parameter를 찾는 것이 궁극적인 목표&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;loss-function--y---fx-손실함수--오차를-구해주는-식&quot;&gt;Loss function = Y - f(x) (손실함수 = 오차를 구해주는 식)&lt;/h4&gt;
&lt;p&gt;Best model은 Loss function이 적은 것 Y - f(x) = 0, ε = 0&lt;/p&gt;

&lt;h4 id=&quot;cost-function--sum--yi---w1-x1i--w2-x2i---2&quot;&gt;Cost function = Sum ( Yi - (w1 X1i + w2 X2i ) ) ^2&lt;/h4&gt;
&lt;p&gt;개별적인 차이를 정의하는 식 // loss function과 비슷한 맥락&lt;/p&gt;

&lt;h3 id=&quot;cost-function을-최소로하는-parameters-w1-w2를-찾자&quot;&gt;Cost function을 최소로하는 parameters (w1, w2)를 찾자&lt;/h3&gt;
&lt;p&gt;^w1, ^w2 (hat)&lt;/p&gt;

&lt;h1 id=&quot;models-parameter를-찾는-것이-핵심&quot;&gt;Model’s parameter를 찾는 것이 핵심&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;how? : throughout given data&lt;/li&gt;
  &lt;li&gt;for what? : to make my prediction to be same as my actual data as much as possible&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>GihoKim</name>
        
        
      </author>

      

      
        <category term="algorithms" />
      

      
        <summary type="html">Algorithms 구성 Algorithms (1) - Machine learning basic 기초 Algorithms (2) - Machine learning linear regression (1) Algorithms (2) - Machine learning linear regression (2) Algorithms (2) - Machine learning linear regression (3) Algorithms (2) - Machine learning linear regression (4)</summary>
      

      
      
    </entry>
  
</feed>
